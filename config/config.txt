[system]
min_vram_mb=7600

[main]
log_level=INFO
graceful_shutdown_ms=5000

[loader]
port=5002
health_interval_ms=2000
restart_backoff_ms=1000,3000,5000
max_restarts_per_minute=3

[kwd]
port=5003
model_path=models/alexa_v0.1.onnx
confidence_threshold=0.6
cooldown_ms=1000
yes_phrases=Yes?;Yes, Master?;Sup?;Yo

[stt]
port=5004
device=cuda
model=small.en
vad_end_silence_ms=2000
max_recording_sec=60
aec_enabled=true
aec_backend=webrtc_aec3

[llm]
port=5005
endpoint=localhost:11434
model=llama3.1:8b-instruct-q4
modelfile_path=config/Modelfile
request_timeout_ms=30000
stream_chunk_chars=80

[tts]
port=5006
voice=af_heart
device=cuda
queue_max_chunks=200
chunk_max_ms=400

[dialog]
followup_window_ms=4000
warmup_greeting=Hi, Master!

[logging]
port=5001
app_reset_on_start=true
rotate_size_mb=10
rotate_keep_files=5
logs_dir=logs